<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><meta name="author" content="OpenTable"><link rel="icon" href="/favicon.png"><title>OpenTable Tech UK Blog</title><meta name="description"><link rel="alternate" type="application/rss+xml" title="OpenTable Tech UK Blog" href="/atom.xml"><link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/main.css"><script src="//fonts.otstatic.com/zys4lfz.js"></script><link rel="stylesheet" href="/css/highlight.css">
</head><body><nav class="navbar navbar-default navbar-fixed-top navbar-custom"><div class="container-fluid"><div class="navbar-header"><button type="button" data-toggle="collapse" data-target="#main-navbar" class="navbar-toggle"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a href="/" class="navbar-brand">OpenTable Tech UK Blog</a></div><div id="main-navbar" class="collapse navbar-collapse"><ul class="nav navbar-nav navbar-right"><li><a href="/about/">About</a></li><li><a href="/archives/">Archive</a></li><li><a href="/blog/authors/">Authors</a></li></ul></div><div class="avatar-container"><div class="avatar-img-border"><a href="/"><img src="/opentable.png" class="avatar-img"></a></div></div></div></nav><div id="header-big-imgs" data-num-img='3' data-img-src-1="/bigimgs/building.jpg" data-img-desc-1="Alphabeta Building" data-img-src-2="/bigimgs/kitchen.jpg" data-img-desc-2="OpenTable London office" data-img-src-3="/bigimgs/office.jpg" data-img-desc-3="OpenTable Engineers"></div><header class="header-section has-img"><div class="intro-header big-img"><div class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class="page-heading"><h1>OpenTable Tech UK Blog</h1><hr class="small"><span class="page-subheading">The technology blog for OpenTable UK.</span></div></div></div></div><span class="img-desc"></span></div></header><div role="main" class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class="posts-list"><article class="post-preview"><a href="/blog/2013/08/05/using-vagrant-to-work-with-elasticsearch-on-your-local-machine/"><h2 class="post-title">Using Vagrant to work with ElasticSearch on your local machine</h2></a><p class="post-meta">Posted on 5 August 2013 · <a href="/blog/categories/ElasticSearch/" class="tag post-meta">ElasticSearch</a> · <a href="/blog/categories/Vagrant/" class="tag post-meta">Vagrant</a> · <a href="/blog/categories/DevOps/" class="tag post-meta">DevOps</a></p><div class="post-entry"><p>Recently, I have started to work a lot more with <a href="http://www.vagrantup.com/" target="_blank" rel="external">Vagrant</a> as a tool for creating a standard development environment across my team. This essentially means that regardless what the developers’ machine is set up or running as, they can still reproduce the same environment as their colleagues just by entering a command. </p>
<p>Configuration managgement is something we have had to embrace to help us maintain an ever changing world of technologies. The hardest thing is knowing what we actually have to build in these environments. We use Vagrant to help us understand this. The simple flow is as follows:</p>
<ul>
<li>Developer starts a new project</li>
<li>Developer creates a Vagrantfile to spin up a local VM</li>
<li>Vagrantfile gets iterated on as the development process goes forward</li>
</ul>
<p>Once the developer understands what they need to actually run their software, we would then go about creating an environment to which this software will actually be deployed for end-to-end testing. I won’t go any further into the details of our Vagrant flow in this post, if you want to read more about how to get started with Vagrant, then I would suggest reading <a href="http://shop.oreilly.com/product/0636920026358.do" target="_blank" rel="external">Vagrant Up and Running</a> by <a href="https://twitter.com/mitchellh" target="_blank" rel="external">Mitchell Hashimoto</a>.</p>
<h2 id="Vagrant-and-ElasticSearch"><a href="#Vagrant-and-ElasticSearch" class="headerlink" title="Vagrant and ElasticSearch"></a>Vagrant and ElasticSearch</h2><p>Whilst reviewing a book on <a href="http://www.elasticsearch.org/" target="_blank" rel="external">ElasticSearch</a>, I noticed how simple the instructions were to get up and running with ElasticSearch. Please note, that there are already lots of Puppet modules for configuring ElasticSearch on <a href="http://forge.puppetlabs.com/modules?q=elasticsearch" target="_blank" rel="external">Puppetlabs Forge</a>. This post only talks about how I was able to quickly spin up some local instances. I didn’t want to manually do this, so I decided to use Vagrant (and Puppet) to take care of it for me. The instructions can be summarised as follows:</p>
<ul>
<li>Download and install the JavaSDK</li>
<li>Download the specific ElasticSearch package</li>
<li>Install ElasticSearch</li>
<li>Download and install curl (to be able to interact with ElasticSearch)</li>
<li>Make sure the service is started</li>
</ul>
<p>I hate doing this manually. Luckily, with the correct script, I am able to automate all of this as follows:</p>
<pre><code>Vagrant.configure(&quot;2&quot;) do |config|
    config.vm.box = &quot;Ubuntu precise 64 VMWare&quot;
    config.vm.box_url = &quot;http://files.vagrantup.com/precise64_vmware.box&quot;
    config.vm.network :forwarded_port, guest: 9200, host: 9200
    config.vm.provision :puppet do |puppet|
        puppet.module_path = &apos;../setup/modules&apos;
        puppet.manifests_path = &apos;../setup/manifests&apos;
        puppet.manifest_file = &apos;default.pp&apos;
        puppet.options = &apos;--verbose --debug&apos;
    end
end
</code></pre><p>Essentially, this script says to create a clone of a VM from a predefined box, forward port 9200 on the vm to 9200 on my local machine and then provision the server using Puppet. The Puppet script works as follows:</p></div><a href="/blog/2013/08/05/using-vagrant-to-work-with-elasticsearch-on-your-local-machine/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2013/07/24/one-gun-many-enemies/"><h2 class="post-title">One Gun - Many Enemies</h2></a><p class="post-meta">Posted on 24 July 2013 · <a href="/blog/categories/Testing/" class="tag post-meta">Testing</a> · <a href="/blog/categories/JavaScript/" class="tag post-meta">JavaScript</a> · <a href="/blog/categories/Jasmine/" class="tag post-meta">Jasmine</a></p><div class="post-entry"><p>I spent some time, re-investigating Javascript. After a few months of intensive TDD and SOLID training at OpenTable I was curious how those principles apply in a slightly different environment. Guess what, they do not differ that much… I planned to write about all this sometime in the future after gaining more experience from real battles ahead, however <a href="http://watirmelon.com/2013/02/09/why-i-dont-like-Jasmine/" target="_blank" rel="external">Watirmelon post</a> invited me to attack this subject immediately.</p>
<p>I went through the available testing frameworks for Javascript and decided on Jasmine. Why? Mainly because of its BDD syntax which is fashionable this season. The second reason is that it has really cool documentation. Finally, the basic set up of just running an HTML file in a browser got me up and running fast.</p>
<p>Let’s look at the basics - what I expect from different types of tests and how Jasmine fits into those requirements: </p>
<h2 id="Unit-Testing"><a href="#Unit-Testing" class="headerlink" title="Unit Testing"></a>Unit Testing</h2><h3 id="Advice-from-senior-craftsman"><a href="#Advice-from-senior-craftsman" class="headerlink" title="Advice from senior craftsman"></a>Advice from senior craftsman</h3><ul>
<li>Shoot them one by one<br>(structure your code so that it is easier to maintain)</li>
<li>Be sure you kill with every shot<br>(verify small bits of code to nail down issues)</li>
<li>Kill them all<br>(verify edge cases)</li>
<li>Kill them quick<br>(provide fast feedback on issues)</li>
<li>Choose a fast shooting gun - the faster you shoot, the more enemies you will kill<br>(unit tests must be blazing fast)</li>
<li>Choose the most reliable gun - if it is stuck then you are dead<br>(when unit tests are brittle you will stop depending on them)</li>
<li>Your gun needs to be light enough to carry everywhere<br>(unit tests are your gun, so you must be able to run them all locally)</li>
</ul>
<p>Jasmine works great for all those aims, as it is really fast and it allows you to stub both objects and DOM elements (especially combined with a Jasmine-jQuery plugin). Keep in mind that Unit Testing is useful only if you either write new code or refactor old code. Do not ever try to write Unit Tests for existing code which you don’t intend to refactor. It’s like shooting the dead. You simply cannot kill them with another bullet.</p>
<h2 id="Integration-Testing"><a href="#Integration-Testing" class="headerlink" title="Integration Testing"></a>Integration Testing</h2><h3 id="Advice-from-senior-craftsman-1"><a href="#Advice-from-senior-craftsman-1" class="headerlink" title="Advice from senior craftsman"></a>Advice from senior craftsman</h3><ul>
<li>Beware of the hidden sniper<br>(test against external dependencies like files, databases, network services)</li>
<li>You are part of your squad<br>(verify that components of the application work well together)</li>
<li>Observe the environment<br>(try to use depenedencies as close to the real problem as possible e.g. example file, database with test data, test version of an external service)</li>
<li>Point in the right direction<br>(do not try to test your stack top-down, instead concentrate on interfaces and adapters that you could not test in unit tests)</li>
</ul></div><a href="/blog/2013/07/24/one-gun-many-enemies/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2013/07/08/managing-windows-certificates-with-powershell/"><h2 class="post-title">Managing Windows Certificates with PowerShell</h2></a><p class="post-meta">Posted on 8 July 2013 · <a href="/blog/categories/Automation/" class="tag post-meta">Automation</a> · <a href="/blog/categories/PowerShell/" class="tag post-meta">PowerShell</a> · <a href="/blog/categories/DevOps/" class="tag post-meta">DevOps</a></p><div class="post-entry"><p>Managing certificates on Windows is <em>really</em> painful. There is no easy way to do it. The general way to install a certificate to a Windows Server 2008 machine is as follows:</p>
<ul>
<li>Open the Certificates snap-in for a user, computer, or service.</li>
<li>In the console tree, click the logical store where you want to import the certificate.</li>
<li>On the Action menu, point to All Tasks, and then click Import to start the Certificate Import Wizard.</li>
<li>Type the file name containing the certificate to be imported. </li>
<li>If you want to specify where the certificate is stored, select Place all certificates in the following store, click Browse, and choose the certificate store to use. OR</li>
<li>If the certificate should be automatically placed in a certificate store based on the type of certificate, click Automatically select the certificate store based on the type of certificate.</li>
</ul>
<p>The first time I ran this process, I felt as though this was just wrong to not be able to automate. The goal of our team is to automate everything we are currently doing manually. PowerShell is a better option for this import process as it allows you to write code to do it. As we all know, code is better for a number of reasons, I won’t go into the infrastructure as code argument in this post (but it is coming soon….). Using PowerShell, I can write a simple function as follows:</p>
<pre><code>function Import-PfxCertificate($certName, $CertLocaton, $certRootStore, $certStore) {    
     $pfx = new-object System.Security.Cryptography.X509Certificates.X509Certificate2    

     $pfxPass = convertto-securestring $CertPassword -asplaintext -force

     $certPath = $CertLocaton + &quot;\&quot; + $certName   
     $pfx.import($certPath,$pfxPass,&quot;Exportable,PersistKeySet&quot;)    

     $store = new-object System.Security.Cryptography.X509Certificates.X509Store($certStore,$certRootStore)    
     $store.open(&quot;MaxAllowed&quot;)    
     $store.add($pfx)    
     $store.close()    
}
</code></pre><p>This makes certificate management easier. To manage certificates in this way, I just need to invoke a script similar to this:</p>
<pre><code>.\import-certificate.ps1 -CertificateName &quot;mycert.pfx&quot; -CertLocation &quot;c:\ssl\mycerts&quot;
</code></pre><p>Much simpler! You can download a <a href="https://gist.github.com/opentable-devops/5951108" target="_blank" rel="external">gist</a> of this script should you wish to use it. Please note that the license that this script is available under can be read from our <a href="https://github.com/opentable/licensing/blob/master/LICENSE" target="_blank" rel="external">github repository</a>. </p>
</div><a href="/blog/2013/07/08/managing-windows-certificates-with-powershell/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2013/06/18/ndcoslo/"><h2 class="post-title">NDC Oslo</h2></a><p class="post-meta">Posted on 18 June 2013 · <a href="/blog/categories/Conferences/" class="tag post-meta">Conferences</a></p><div class="post-entry"><p>Three OpenTable heroes took to Norway last week to attend NDC Oslo. For two of us it was our first major conference and for one, Paul Stack, he had to speak.</p>
<p>Personally, as my first large, multi-discipline conference, I didn’t really know what to expect. Being away from the team for three days in a foreign country with major project work going on at the same time was a bit uncomfortable. I was worried that the time and expense needed to be justified. That fear went away after the first night in the bar!</p>
<p>The sessions were great, many things I haven’t had a chance to investigate were covered, things like Functional Programming, the latest JavaScript frameworks and tooling. There were also sessions covering things I am more involved with, Agile Process, SOA &amp; Rest, Team Structure and Hiring.</p>
<p>There are other posts around about the individual sessions but I am now much more enthusiastic about functional programming particularly how we could use it and getting back into front end development (even if just in my own time).</p>
<p>The main thing I enjoyed and learnt though is meeting the other delegates. I think staying away from home makes this much more prevalent, something to consider for other conferences. Meeting people at all levels or experience and especially the speakers, most of whom are very generous with their time and ideas, teaches you the most. I probably learnt more over the shuffle board of The Dubliner Pub than reading blog post online in a year (that may be a stretch, but I did learn I was by far the best player on the night). </p>
<p>Watching a colleague speak was also interesting, when you work with a buffoon, however passionate and hard working, to see people actually interested in what he has to say is an eye opener. It makes you realise what you are doing and all its challenges are a step forwards and one to keep pursuing. It also makes you think, “if he can do it, I must be able to, what knowledge should I share?”. What to share is the hard bit.</p>
<p>My final point is how often I should try to get to these; one a year for sure, any more than that? I need to think that through.</p>
<p>Thanks to the organisers of the conference for a well organised, varied and enjoyable time. And if you have project work on, the wifi was excellent so you need never be too far away from the rest of the team, just do it.</p>
</div><a href="/blog/2013/06/18/ndcoslo/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2013/06/14/windows-feature-management-with-powershell/"><h2 class="post-title">Windows Feature Management with PowerShell</h2></a><p class="post-meta">Posted on 14 June 2013 · <a href="/blog/categories/Automation/" class="tag post-meta">Automation</a> · <a href="/blog/categories/PowerShell/" class="tag post-meta">PowerShell</a> · <a href="/blog/categories/DevOps/" class="tag post-meta">DevOps</a></p><div class="post-entry"><p>In late 2012, our development team started to move towards our systems being much more automated. Long gone are the days of developers creating runbooks in Word and giving them to our operations team to use to set up our production servers. </p>
<p>When building our webservers on Windows, in order to install / activate Windows features, this was the general set of instructions that was needed to be followed:</p>
<ul>
<li>Click Start Button</li>
<li>Click on Control Panel</li>
<li>Click on Programs</li>
<li>Click on Turn Windows features on or off</li>
</ul>
<p>This would present a screen as follows:</p>
<img src="/images/posts/windowsfeature.png" class="center">
<p>You would need to find the correct features to enable and check the box, press OK and then wait for the features to be installed. </p>
<p>When Microsoft introduced Windows Server 2008 and PowerShell 2.0, they also introducted the module ‘ServerManager’. This is a module that allows us to interact, with PowerShell, Windows Features using a range of cmdlets:</p>
<ul>
<li>Get-WindowsFeature</li>
<li>Add-WindowsFeature</li>
<li>Remove-WindowsFeature</li>
</ul>
<p>This meant that instead of creating runbooks in Word, our developers could create automation scripts that would take a base Windows Server 2008 server and enable all the Windows Features needed to run our applications. This allowed our operations team to move much faster in configuring our servers. </p>
<p>To turn on the ASP.NET Application Development features in Windows, we would run the following script from PowerShell:</p></div><a href="/blog/2013/06/14/windows-feature-management-with-powershell/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2013/06/07/nlocalgeocoder/"><h2 class="post-title">nLocalGeoCoder</h2></a><p class="post-meta">Posted on 7 June 2013 · <a href="/blog/categories/OSS/" class="tag post-meta">OSS</a> · <a href="/blog/categories/Net/" class="tag post-meta">.Net</a> · <a href="/blog/categories/C/" class="tag post-meta">C#</a> · <a href="/blog/categories/Ruby/" class="tag post-meta">Ruby</a> · <a href="/blog/categories/Collaboration/" class="tag post-meta">Collaboration</a></p><div class="post-entry"><h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><p>With OpenTable having engineering teams spread across multiple offices it’s important for us to maintain open email dialogue about new products us or our teams have created, new tools we’ve discovered or problem solving approaches that have helped us achieve our goals.  Recently in one of these emails Aish introduced the team to a new open source ruby implementation of reverse geocode lookup for latitude and longitude he’d written called <a href="https://github.com/aishfenton/local-geocoder" target="_blank" rel="external">local-geocoder</a>.  With an interest in understanding how this worked, to learn a bit of ruby, to make this project accessible to .net developers and just to see how long it would take I decided to port it to C# and .net.</p>
<h2 id="How-reverse-geocoding-works"><a href="#How-reverse-geocoding-works" class="headerlink" title="How reverse geocoding works"></a>How reverse geocoding works</h2><p>Latitude and longitude geographical coordinates are great but 37.819548,-122.479046 doesn’t really mean much to me. Knowing this is in the San Francisco bay area is much more useful interpretation.</p>
<p>That’s where reverse geocoding comes in.  Normally geocoding tries to locate geographical coordinates from other data like postal (zip) codes or street level addresses.  Reverse geocoding does the opposite and can, given enough lookup data, be very precise.</p>
<p>There are a number of online reverse geocoding providers, like Google, who can perform this for you however there are normally usage limits or costs for using them.  To add to this the latency of these service can slow your logic down.  Wouldn’t it be nice if this could be done locally at high speed and in memory.</p>
<h2 id="Using-nLocalGeocoder"><a href="#Using-nLocalGeocoder" class="headerlink" title="Using nLocalGeocoder"></a>Using nLocalGeocoder</h2><p>It’s really easy to use, just new up a Geocoder and you’re off…</p>
<pre><code>var geocoder = new Geocoder();
var result = geocoder.ReverseGeocode(-122.479046M, 37.819548M);
</code></pre><p>The result variable now holds an instance of the Result struct.  This type has the following properties:-</p></div><a href="/blog/2013/06/07/nlocalgeocoder/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2013/06/07/getting-started-with-specrun/"><h2 class="post-title">Getting Started With SpecRun</h2></a><p class="post-meta">Posted on 7 June 2013 · <a href="/blog/categories/Acceptance-tests/" class="tag post-meta">Acceptance tests</a> · <a href="/blog/categories/SpecRun/" class="tag post-meta">SpecRun</a> · <a href="/blog/categories/Automation/" class="tag post-meta">Automation</a> · <a href="/blog/categories/CI/" class="tag post-meta">CI</a></p><div class="post-entry"><h2 id="First-some-background"><a href="#First-some-background" class="headerlink" title="First some background"></a>First some background</h2><p>We recently switched from writing automated acceptance from Cucumber to SpecFlow… this is no slight on Cucumber it’s just that we had a lot of C# developers who wanted to get closer to writing acceptance tests. Worth adding that SpecFlow has also come a long way as a .Net port of Cucumber and is pretty much like for like now.</p>
<h2 id="Why-should-I-bother-with-SpecRun"><a href="#Why-should-I-bother-with-SpecRun" class="headerlink" title="Why should I bother with SpecRun?"></a>Why should I bother with SpecRun?</h2><p>Initially we ran our entire unit, integration and acceptance tests via nUnit. Pretty much industry standard but we felt nUnit wasn’t really a good tool to run acceptance tests - yes it’ll do the job but we were looking for better performance, quicker failure feedback and more comprehensive reporting. If you want details on SpecRun vs. nUnit Gasper has a <a href="http://gasparnagy.com/2011/09/specrun-because-integration-tests-are-not-unit-tests/" target="_blank" rel="external">great blog post</a>.</p>
<salespitch>SpecRun itself is free to use although there is a random delay when running acceptance locally, setting up SpecRun on a CI environment is totally free and does not include the same delay. Definitely worth trying out and you can purchase a licence later if you like what it offers.</salespitch>

<h2 id="Installing-SpecRun"><a href="#Installing-SpecRun" class="headerlink" title="Installing SpecRun"></a>Installing SpecRun</h2><p>If you are already using SpecFlow with nUnit the migration to SpecRun is really simple - <a href="http://www.youtube.com/watch?v=c2ge90BWeI0" target="_blank" rel="external">this video</a> shows you how to setup the test runner but I found myself having to watch it too many times. This post is an attempt at recording the steps should we roll out SpecRun for another project.  </p>
<p>I’m assuming you’re running Visual Studio and are familiar with Nuget packages. I’ll break it down so I don’t miss anything:</p>
<ol>
<li>In VS, select your Acceptance test project and get the Nuget package down for SpecRun: <code>install-package SpecRun</code>.</li>
<li>You’ll notice Nuget automatically adds configuration to your app.config so it’s safe to remove the nUnit provider setting (this is to enable you to pick and choose your test runner but we prefer to only use SpecRun).</li>
<li>Open the Default.srprofile file and we normally delete any commented settings here.</li>
<li>Still inside Default.srprofile add the properties for projectName and projectId. The projectName is what you see in VS the projectId can be found by opening the acceptance .proj file and taking the projectGuid.</li>
<li>Setup the execution properties - this really depends on what you want to get out of running the tool - what retry count you want, whether to run on multiple threads, etc. Here are the values we normally use:</li>
</ol>
<p><code>&lt;Execution retryFor=&quot;None&quot; stopAfterFailures=&quot;100&quot; testThreadCount=&quot;1&quot; testSchedulingMode=&quot;Sequential&quot; apartmentState=&quot;STA&quot;/&gt;</code></p></div><a href="/blog/2013/06/07/getting-started-with-specrun/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2013/06/01/about-this-blog/"><h2 class="post-title">Welcome to the OpenTable UK technology blog</h2></a><p class="post-meta">Posted on 1 June 2013</p><div class="post-entry"><p>Hi, my name is Paul Harrington and I’d like to welcome you to the <a href="http://www.opentable.co.uk" target="_blank" rel="external">OpenTable UK</a> technology blog &ndash; a place where we’d like to share our passions and introduce you to a whole new world of fabulous dining and amazing technology.</p>

<h2>Who are we?</h2>

<p>First and foremost we’re into food. And restaurants. And delighting our diners with wonderful dining experiences. And if you want to hear more from us about <i>these</i> passions then pay a visit to the <a href="http://blog.opentable.co.uk" target="_blank" rel="external">OpenTable UK blog</a> or the <a href="http://press.opentable.co.uk" target="_blank" rel="external">OpenTable UK Press Centre</a> and follow <a href="https://twitter.com/opentableuk" target="_blank" rel="external">@OpenTableUK</a> on Twitter &ndash; because on this blog you’re only going to hear about our love of technology and all the cool stuff we do with it!<br><br></p><p>But first some introduction is needed. I am the Senior Director of Engineering and have worked at OpenTable for four years. My principal goal is to create environments where awesome teams of Engineers can build awesome software! The specific journey we’ve been through to achieve this is a topic for another day but there is one key message that is worth sharing. When I first arrived, I had a dream that I shared with the team &ndash; <b>to create the best engineering team in the UK</b>. It was an ambitious target and we don’t really have an effective way of testing whether we’ve been successful in that goal. But the consistent belief in achieving that vision was enough to at least make it feel true and it has led to some spectacular results, some of which you will read about on here.</p>

<h2>What do we do?</h2>

<h3>We build great software.</h3>

<p>We’re passionate about high quality code and we use cutting-edge technologies and techniques to achieve it. The core of our system is built in .Net so we have a lot of expertise in this area but we’re not limited to a single language. We like to explore new languages and look to apply it wherever it is relevant. We’re meticulous in the code we write but pragmatic when necessary to deliver the best results for the business. Legacy code is in trouble as we look for every opportunity to get rid of it, but that in itself is never the goal &ndash; the goal is to build great software that delivers value to our customers.</p>

<h3>We believe in testing.</h3>

<p>We test everything we produce to within an inch of its life. We employ TDD and BDD at a unit level and we create suites of integration tests and business readable acceptance tests. We build performance tests, load tests and smoke tests and have our systems continuously monitored so we can spot when issues occur. And we do this all within the Engineering team, there is no “throwing over the wall” to a separate QA team that does all the testing &ndash; the teams of Engineers themselves are responsible for the quality of our systems.</p>

<h3>We move fast.</h3></div><a href="/blog/2013/06/01/about-this-blog/" class="post-read-more">[Read More]</a></article></div><ul class="pager main-pager"><li class="previous"><a href="/page/5">← Newer Posts</a></li></ul></div></div></div><footer><div class="container beautiful-jekyll-footer"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href="https://github.com/opentable" title="GitHub"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-github"></i></span></a></li><li><a href="https://twitter.com/opentabletechuk" title="Twitter"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-twitter"></i></span></a></li><li><a href="https://www.linkedin.com/company/12181" title="LinkedIn"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-linkedin"></i></span></a></li><li><a href="http://stackoverflow.com/jobs/companies/opentable" title="StackOverflow"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-stack-overflow"></i></span></a></li></ul><p class="copyright text-muted">© OpenTable • 2016 • <a href="mailto:undefined"></a>
</p><p class="theme-by text-muted">Theme by
<a href="https://github.com/twoyao/beautiful-hexo">beautiful-hexo</a></p></div></div></div></footer><script src="/js/jquery-1.11.2.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/main.js"></script><script src="/js/highlight.min.js"></script><script>hljs.initHighlightingOnLoad();</script><script>(function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r;
    i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
    a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    m.parentNode.insertBefore(a, m)
})(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
ga('create', 'UA-2621903-16', 'auto');
ga('send', 'pageview');</script></body></html>