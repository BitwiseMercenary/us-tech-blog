<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><meta name="author" content="OpenTable"><link rel="icon" href="/favicon.png"><title>OpenTable Tech UK Blog</title><meta name="description"><link rel="alternate" type="application/rss+xml" title="OpenTable Tech UK Blog" href="/atom.xml"><link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/main.css"><script src="//fonts.otstatic.com/zys4lfz.js"></script><link rel="stylesheet" href="/css/highlight.css">
</head><body><nav class="navbar navbar-default navbar-fixed-top navbar-custom"><div class="container-fluid"><div class="navbar-header"><button type="button" data-toggle="collapse" data-target="#main-navbar" class="navbar-toggle"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a href="/" class="navbar-brand">OpenTable Tech UK Blog</a></div><div id="main-navbar" class="collapse navbar-collapse"><ul class="nav navbar-nav navbar-right"><li><a href="/about/">About</a></li><li><a href="/archives/">Archive</a></li><li><a href="/blog/authors/">Authors</a></li></ul></div><div class="avatar-container"><div class="avatar-img-border"><a href="/"><img src="/opentable.png" class="avatar-img"></a></div></div></div></nav><div id="header-big-imgs" data-num-img='3' data-img-src-1="/bigimgs/building.jpg" data-img-desc-1="Alphabeta Building" data-img-src-2="/bigimgs/kitchen.jpg" data-img-desc-2="OpenTable London office" data-img-src-3="/bigimgs/office.jpg" data-img-desc-3="OpenTable Engineers"></div><header class="header-section has-img"><div class="intro-header big-img"><div class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class="page-heading"><h1>OpenTable Tech UK Blog</h1><hr class="small"><span class="page-subheading">The technology blog for OpenTable UK.</span></div></div></div></div><span class="img-desc"></span></div></header><div role="main" class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class="posts-list"><article class="post-preview"><a href="/blog/2014/05/13/managing-windows-web-applications-with-puppet/"><h2 class="post-title">Managing Windows Web Applications with Puppet</h2></a><p class="post-meta">Posted on 13 May 2014 · <a href="/blog/categories/Puppet/" class="tag post-meta">Puppet</a> · <a href="/blog/categories/PowerShell/" class="tag post-meta">PowerShell</a> · <a href="/blog/categories/DevOps/" class="tag post-meta">DevOps</a> · <a href="/blog/categories/Configuration-Management/" class="tag post-meta">Configuration Management</a> · <a href="/blog/categories/Windows/" class="tag post-meta">Windows</a> · <a href="/blog/categories/IIS/" class="tag post-meta">IIS</a></p><div class="post-entry"><p>As part of our move towards a configuration management tool, we really wanted to start automating as much of our infrastructure as possible. This included our application configuration stack. IIS management is pretty easy with PowerShell. It would look something like this</p>
<pre><code>Import-Module WebAdministration
New-WebSite -Name &quot;DemoSite&quot; -Port 80 -IP * -PhysicalPath &quot;c:\inetpub\wwwroot&quot; -ApplicationPool &quot;MyAppPool&quot;
</code></pre><p>This would of course set up a website called ‘DemoSite’ running on port 80 on the local machine. The cmdlets that come with PowerShell make this pretty easy. This is great if it is a one-off job to set up a site. We run our websites from a number of webservers, therefore, it would be silly to have to RDP into each webserver and run a script on it. This is why tools like Puppet, Chef, Ansible etc. exist. We needed a configuration management tool to do this work for us. It has a number of benefits:</p>
<ul>
<li>Orchestration</li>
<li>Idempotency</li>
<li>Makes sure that each server is configured in ‘exactly’ the same way as no human intervention is needed</li>
<li>Developers can help the operations team by creating the scripts needed. This is great for collaboration between teams</li>
</ul>
<p>On investigating how we would do this with Puppet, we noticed that there were not many other people managing their site in this way. Therefore, we would have to turn our PowerShell scripts into Puppet modules to manage our system. </p>
<p>We have since created a Puppet module to manage IIS. To manage IIS with Puppet, we can now write the following code:</p>
<pre><code>iis::manage_site { &apos;DemoSite:
   site_path     =&gt; &apos;c:\inetpub\wwwroot&apos;,
   port          =&gt; &apos;80&apos;,
   ip_address    =&gt; &apos;*&apos;,
   app_pool      =&gt; &apos;MyAppPool&apos;
}
</code></pre><p>This would produce <strong>exactly</strong> the same results as the code from above. But it has 1 difference. There are checks in the code behind this module that will mean the code will only execute when it is needed, i.e. when the site_path isn’t correct or the app_pool isn’t correct. This is idempotency. The script can be run again and again and again….</p>
<p>To create an application binding, we used to do this in PowerShell:</p>
<pre><code>Import-Module WebAdministration
New-WebBinding -Name &apos;DemoSite&apos; -Port &apos;8080&apos; -IPAddress &apos;*&apos;
</code></pre></div><a href="/blog/2014/05/13/managing-windows-web-applications-with-puppet/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/04/28/remote-worker-notes-tools-and-setup/"><h2 class="post-title">Remote Worker Notes &ndash; Tools and Setup</h2></a><p class="post-meta">Posted on 29 April 2014 · <a href="/blog/categories/Work-smarter/" class="tag post-meta">Work smarter</a> · <a href="/blog/categories/Culture/" class="tag post-meta">Culture</a> · <a href="/blog/categories/Agile/" class="tag post-meta">Agile</a> · <a href="/blog/categories/Remote-working/" class="tag post-meta">Remote working</a></p><div class="post-entry"><p>For the last couple months I’ve been working remotely with our search team at OpenTable. Let me share our remote working setup and some rationale for our choices. I will shy away from judging how it’s all worked out and leave that for subsequent blog posts.</p>
<h2 id="The-deal"><a href="#The-deal" class="headerlink" title="The deal"></a>The deal</h2><p>I started as an on-site engineer and subsequently became a remote worker and my challenge was to make remote working as similar to on-site working as possible. Thus it is natural that <strong>I work the same working hours</strong> as my colleagues in the office (despite the time difference) and I take <strong>public holidays</strong> at the same time that there are bank holidays in UK (even though in Poland they are different).</p>
<p>We also decided that every two months I will <strong>visit the office for a week</strong> as well as arranging visits to coincide with other office guests (like contractors, overseas colleagues and so on). All this is to try to keep me as close to the team as possible and disrupt the normal work-flow as little as possible.</p>
<h2 id="The-workplace-setup"><a href="#The-workplace-setup" class="headerlink" title="The workplace setup"></a>The workplace setup</h2><p>Once home in Poland I had to carefully consider my options for a workplace. I tried three obvious possibilities:</p>
<ul>
<li>Dining room in my own one bedroom flat</li>
<li>Co-working space</li>
<li>Private room in my parents’ house</li>
</ul>
<p>The <strong>dining room</strong> worked pretty well, for a time…  I would ‘arrive’ really early in the office (just after taking a shower), and then be ‘home’ straight after the laptop lid was closed. My wife kindly respected that I am focused at work and distracted me only to share lunch (or to kick me out of house to bring the lunch in).</p>
<p>A couple of things made it only a short-term solution - the first being my back complaining about working on a chair that’s nice for a dinner, but awful for working on computer. Then I realised that I really miss a second monitor and separate keyboard &ndash; I guess anybody who coded in the middle of summer on a laptop knows the pain of a hot computer under your fingers.  Finally, my child was born, and that was it &ndash; a crying child in the same room when you are trying to pair with somebody is a deal-breaker.</p>
<p>In the meantime I evaluated a local <strong>co-working space</strong>. The problem was that it was quiet, <em>really quiet</em>, up to the point that I was embarrassed to pair with somebody remotely. The way we work fluctuates over time; there are weeks when I do stuff alone and in silence, there are weeks when I spend whole days on conversations or pairing. I just cannot be too quiet. For that matter I tried also a coffee shop, but it failed me for exactly the same reasons as the dining room table.</p></div><a href="/blog/2014/04/28/remote-worker-notes-tools-and-setup/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/04/27/effective-prioritisation/"><h2 class="post-title">Effective prioritisation</h2></a><p class="post-meta">Posted on 28 April 2014 · <a href="/blog/categories/Leadership/" class="tag post-meta">Leadership</a> · <a href="/blog/categories/Coaching/" class="tag post-meta">Coaching</a> · <a href="/blog/categories/Work-smarter/" class="tag post-meta">Work smarter</a> · <a href="/blog/categories/Culture/" class="tag post-meta">Culture</a></p><div class="post-entry"><p>Prioritisation is a huge part of modern life.</p>
<p>No.</p>
<p>Prioritisation is an ESSENTIAL part of modern life.</p>
<p>I’m not talking solely about Agile here either. Yes we plan stories, yes we prioritise them to get them into the backlog but I’m aiming at a higher level. Life lessons that are useful to all of us.</p>
<p>How do we know what to do next? Perhaps you lean on your gut feeling to order your to-do list. Maybe it is real-time cost and budget implications that influence your priorities or does it come down to who shouts loudest?</p>
<h2 id="Why-is-prioritisation-important"><a href="#Why-is-prioritisation-important" class="headerlink" title="Why is prioritisation important?"></a>Why is prioritisation important?</h2><p>The experts would have us believe we are living through the Digital Age, also know as the Computer Age. Increasingly this has been more accurately redefined as the Information Age. </p>
<p>The society we live in today truly bombardes us with information. Whether it be TV, mobile, emails, blog posts, status updates, tweets, likes and check-in’s we are rarely unconnected to modern day life and have a vast amount of data and information at our disposal.</p>
<p>This flood of information leads to a problem: we often confuse the importance of everyday tasks and activities. </p>
<p>For instance how many times have we said “I don’t have time to read” or “I’d love to be able to go to the gym more”. Perhaps a more honest way to say this is “reading is not a high priority for me” or “I prioritise other activities higher than going to the gym”. </p></div><a href="/blog/2014/04/27/effective-prioritisation/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/04/16/look-ma-no-unit-tests/"><h2 class="post-title">Look ma, no unit tests!</h2></a><p class="post-meta">Posted on 16 April 2014 · <a href="/blog/categories/Engineering/" class="tag post-meta">Engineering</a> · <a href="/blog/categories/Testing/" class="tag post-meta">Testing</a> · <a href="/blog/categories/Acceptance-tests/" class="tag post-meta">Acceptance tests</a> · <a href="/blog/categories/Innovation/" class="tag post-meta">Innovation</a></p><div class="post-entry"><p><em><strong>UPDATE:</strong> I’ve written a <a href="/blog/2014/05/19/acceptance-now">follow-up to this post</a> with a bit more detail into how we made acceptance-only testing work in practice.</em></p>
<p>At OpenTable we strive to deliver change as quickly and correctly as possible. To do this effectively we are always looking for <a href="/blog/2014/02/28/api-benchmark/">new</a> <a href="/blog/2013/08/16/grunt-plus-vagrant-equals-acceptance-test-heaven/">tools</a> <a href="/blog/2014/04/07/upgrading-puppet-with-puppet/">and</a> <a href="/blog/2014/02/10/the-adoption-of-configuration-management/">methods</a> that allow us, the developers, to respond quickly and accurately to changing requirements and environments.</p>
<p>There are a number of practices that we already make use of, helping us to be the most effective team I’ve ever worked in:</p>
<ul>
<li>We operate in small teams who each own <em>most</em> of their own vertical.</li>
<li>We use continuous delivery to ship code to production within minutes.</li>
<li>We have a high degree of high-quality test coverage.</li>
<li>We are getting better and better at monitoring All The Things.</li>
<li><a href="/blog/2013/11/22/beginning-a-journey-to-chatops-with-hubot/">We use Chatops</a>, so communication is central to our work, and keeps remote workers/teams in the loop.</li>
</ul>
<p>All of the above are truly empowering for the dev team, and are conducive to an amazingly stress-free working environment. However, these practices only address the infrastructure, culture, and ceremony surrounding our work. What if there was something else? Something about the way we write the code itself, that could increase our velocity yet further, without compromising our integrity…</p>
<blockquote>
<p>There are a number of practices that we already make use of, helping us to be the most effective team I’ve ever worked in… What if there was something else?</p>
</blockquote>
<p>Well, on a recent project, we found one such way: <em><em>we decided to delete all of the unit and integration tests</em></em>.</p>
<p><em>What?! Are we quite mad?</em> You may be thinking… Well, it took me a little time to get used to this idea as well, but read on and you’ll see that it was actually the most sane thing we could have possibly done    .</p>
<h2 id="Survival-of-the-testedest"><a href="#Survival-of-the-testedest" class="headerlink" title="Survival of the testedest"></a>Survival of the testedest</h2><p>In the beginning, the project had 100% unit test coverage, there were no external dependencies, and the world was Good.</p></div><a href="/blog/2014/04/16/look-ma-no-unit-tests/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/04/07/upgrading-puppet-with-puppet/"><h2 class="post-title">Upgrading Puppet with Puppet</h2></a><p class="post-meta">Posted on 7 April 2014 · <a href="/blog/categories/Puppet/" class="tag post-meta">Puppet</a> · <a href="/blog/categories/Windows/" class="tag post-meta">Windows</a> · <a href="/blog/categories/Maintenance/" class="tag post-meta">Maintenance</a> · <a href="/blog/categories/Puppetversion/" class="tag post-meta">Puppetversion</a></p><div class="post-entry"><p>As part of one of our recent <a href="/blog/2014/04/04/forgefriday-our-commitment-to-the-puppet-forge/">ForgeFriday</a> efforts we released a new module puppetversion with the purpose of managing the installation and upgrade of Puppet in a platform agnostic way.</p>
<p>This should be a very straightforward task to complete because this is one of the core resources that Puppet manages - the upgrading of packages. With that in mind, putting <code>package { ‘puppet’: ensure =&gt; $version }</code> in one of our base profiles would be all that was needed but alas it was not. In this blog I want to take you through the history, the bugs, the platforms and the edge-cases that make performing an in-place upgrade of Puppet a more complex task that it ought to be.</p>
<h2 id="Debian"><a href="#Debian" class="headerlink" title="Debian"></a>Debian</h2><p>Like many, Ubuntu is our Debian derivative of choice for much of our newer production infrastructure. Debian, has the apt package management system and PuppetLabs provide the required deb packages as well as hosting their own apt repository to point our systems to. The main point of package management systems is that they take care of the dependency hell and the awkward upgrade paths all from within the confines of the package itself, and that is what happens with the PuppetLabs packages - great. </p>
<p>The problem that we had in some of our systems was that they had been built without the PuppetLabs apt repository. This means that they picked up a slightly older version of the Puppet packages from the main Ubuntu distribution repositories and didn’t have access to the newer versions of the Puppet packages. Ok, so we solved that with the following code:</p>
<pre><code>exec { &apos;rm_duplicate_puppet_source&apos;:
  path    =&gt; &apos;/usr/local/bin:/bin:/usr/bin&apos;,
  command =&gt; &apos;sed -i \&apos;s:deb\ http\:\/\/apt.puppetlabs.com\/ precise main::\&apos; /etc/apt/sources.list&apos;,
  onlyif  =&gt; &apos;grep \&apos;deb http://apt.puppetlabs.com/ precise main\&apos; /etc/apt/sources.list&apos;,
}

apt::source { &apos;puppetlabs&apos;:
  location    =&gt; &apos;http://apt.puppetlabs.com&apos;,
  repos       =&gt; &apos;main dependencies&apos;,
  key         =&gt; &apos;4BD6EC30&apos;,
  key_content =&gt; template(&apos;puppetversion/puppetlabs.gpg&apos;),
  require     =&gt; Exec[&apos;rm_duplicate_puppet_source&apos;]
}
</code></pre><p>We’re making use of the <a href="http://forge.puppetlabs.com/puppetlabs/apt" target="_blank" rel="noopener">puppetlabs/apt</a> module here. This removes the old reference and adding in the new apt source. Then we just add the package and ensure the version we’re upgrading. Perfect.</p>
<h2 id="RedHat"><a href="#RedHat" class="headerlink" title="RedHat"></a>RedHat</h2><p>Same problem different OS family - this time we had some older CentOS machines that needed fixing. Thankfully there is also a module <a href="http://forge.puppetlabs.com/stahnma/puppetlabs_yum" target="_blank" rel="noopener">stahnma/puppetlabs_yum</a> for the yum repositories. Add that in, add the package resource and start upgrading. Phew! This seems like it’s getting easier.</p>
<h2 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h2></div><a href="/blog/2014/04/07/upgrading-puppet-with-puppet/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/04/04/testing-puppet-with-beaker/"><h2 class="post-title">Testing Puppet with Beaker</h2></a><p class="post-meta">Posted on 4 April 2014</p><div class="post-entry"><p>One afternoon I got asked to write a new Puppet module to manage local users on our Linux boxes. Not a contrived example but a real-world need as we begin to move our infrastructure from Windows to Linux. Managing users is one of those tasks that is at the core of the Puppet ecosystem and I thought this would be pretty easy as I had done this sort of thing many times before. What added to the complexity was that we needed to support Ubuntu, Centos and FreeBSD machines that we had in our stack and we wanted to make it something that was open source and on the Forge - so lots of testing was required.</p>
<p>This was not the first module that I had written for the Forge but it was the first that I had written since PuppetLabs had introduced their new acceptance testing framework <a href="https://github.com/puppetlabs/beaker" target="_blank" rel="noopener">Beaker</a> and so I wanted to spend some time getting the module working with this new tool.</p>
<h2 id="Beaker"><a href="#Beaker" class="headerlink" title="Beaker"></a>Beaker</h2><p>The purpose of Beaker is to allow you to write acceptance tests for your modules, that is to write some manifests that use your module and test them out on a virtual machine. Some of you may remember <a href="https://github.com/puppetlabs/rspec-system-puppet" target="_blank" rel="noopener">rspec-system-puppet</a> was previously used to accomplish this, well PuppetLabs has since deprecated that in favour of Beaker but the premise is very much the same.</p>
<p>Using rspec-puppet for unit testing your manifests really only goes so far. If you’re just using the standard Puppet resources then it pretty safe to assume that it does what it says on the tin (I mean PuppetLabs really test their stuff!) but as soon as you start doing things that are a little more complex, using exec statements, custom facts, custom functions or targeting multiple operating systems then you’re really going to want to make sure that once the catalogs compile that they are doing what they are meant to be doing and this is where your acceptance test suite will come in.</p>
<p>With Beaker you can spin up a virtual machine, install modules, apply a manifest and then test what really happened.</p>
<p>Beaker works with many different hypervisor technologies but most people will be using <a href="http://www.vagrantup.com/" target="_blank" rel="noopener">Vagrant</a> so that is what I will cover here.</p>
<h3 id="Configuring-Beaker"><a href="#Configuring-Beaker" class="headerlink" title="Configuring Beaker"></a>Configuring Beaker</h3><p>The first thing in configuring your existing project to use Beaker is to add “beaker” and “beaker_rspec” to you Gemfile. You’re then going to want to create a new spec_helper file called spec_helper_acceptence.rb that should look something like this:</p>
<pre><code>require &apos;beaker-rspec/spec_helper&apos;
require &apos;beaker-rspec/helpers/serverspec&apos;

hosts.each do |host|
  install_puppet
end

UNSUPPORTED_PLATFORMS = [&apos;Suse&apos;,&apos;windows&apos;,&apos;AIX&apos;,&apos;Solaris&apos;]

RSpec.configure do |c|
  proj_root = File.expand_path(File.join(File.dirname(__FILE__), &apos;..&apos;))

  c.formatter = :documentation

  # Configure all nodes in nodeset
  c.before :suite do
    puppet_module_install(:source =&gt; proj_root, :module_name =&gt; &apos;homes&apos;)
    hosts.each do |host|
      on host, puppet(&apos;module&apos;,&apos;install&apos;,&apos;puppetlabs-stdlib&apos;), { :acceptable_exit_codes =&gt; [0,1] }
      on host, puppet(&apos;module&apos;, &apos;install&apos;, &apos;opentable-altlib&apos;), { :acceptable_exit_codes =&gt; [0,1] }
    end
  end
end
</code></pre></div><a href="/blog/2014/04/04/testing-puppet-with-beaker/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/04/04/forgefriday-our-commitment-to-the-puppet-forge/"><h2 class="post-title">ForgeFriday - our commitment to the Puppet Forge</h2></a><p class="post-meta">Posted on 4 April 2014 · <a href="/blog/categories/OSS/" class="tag post-meta">OSS</a> · <a href="/blog/categories/Puppet/" class="tag post-meta">Puppet</a> · <a href="/blog/categories/Open-souce/" class="tag post-meta">Open souce</a></p><div class="post-entry"></div><a href="/blog/2014/04/04/forgefriday-our-commitment-to-the-puppet-forge/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/04/02/internationalisation-in-a-restful-world/"><h2 class="post-title">Internationalisation in a RESTful world</h2></a><p class="post-meta">Posted on 2 April 2014 · <a href="/blog/categories/REST/" class="tag post-meta">REST</a> · <a href="/blog/categories/API/" class="tag post-meta">API</a> · <a href="/blog/categories/i18n/" class="tag post-meta">i18n</a> · <a href="/blog/categories/Internationalisation/" class="tag post-meta">Internationalisation</a> · <a href="/blog/categories/http/" class="tag post-meta">http</a></p><div class="post-entry"><p>I18n is often a painful afterthought when serving content from a http-api. It can be taken for granted and tacked on using nasty query string values. But thankfully HTTP provides us with a solid gold opportunity. If you can look past the mire of content negotiation you can see the nuggets that lie inside.</p>
<p>The accept-language header is used by most browsers and allows websites to serve content in a language that the user can (hopefully) understand. When we expose content from an api (in most of our use cases, at least), this content eventually ends up in front of a human (in some shape or form). Having our service-service communication serve localised resources can be invaluable because it frees the clients from having to think about i18n of the resources being served from our api.</p>
<p>It is a simple part of the HTTP specification and is widely used and supported.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET /product/123</span><br><span class="line">Accept-Language: en-US</span><br></pre></td></tr></table></figure>
<p>The accept-language header is specifically designed to allow the server to provide a representation of the resource which approximates something the client can understand.</p>
<p>The really useful bit comes from the quality value. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET /product/123</span><br><span class="line">Accept-Language: en-US,en;q=0.8</span><br></pre></td></tr></table></figure>
<p>This header asks the service to provide en-US, and if it’s unavailable then fall back to <strong>any</strong> english representation. The quality value (<code>q=0.8</code>) is a decimal value between 0 and 1 which indicates order of preference when specifying multiple languages. The server should pick the <strong>first</strong> available match. If there are multiple matches with the same quality value, then the server can pick any. If the client wants to specify some fierce preferences then they can crank out something like this:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET /product/123</span><br><span class="line">Accept-Language: fr-CA,fr-FR;q=0.8,fr;q=0.6,en-US;q=0.4,en;q=0.2,*;q=0.1</span><br></pre></td></tr></table></figure>
<p>If you decipher this it’s pretty simple, you can see the quality headers giving the order in which the languages are preferred. What it does is give the client fantastic flexibility. For service-service communication you might have a use-case which will <em>never</em> serve a representation that doesn’t match the request, or you might need to <em>always</em> provide some representation (i.e. for cases where some content is always better than none).</p></div><a href="/blog/2014/04/02/internationalisation-in-a-restful-world/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/03/20/when-to-performance-test-in-production/"><h2 class="post-title">When to performance test in production</h2></a><p class="post-meta">Posted on 20 March 2014 · <a href="/blog/categories/Performance/" class="tag post-meta">Performance</a></p><div class="post-entry"><p>In <a href="/blog/2014/03/19/performance-testing-our-search-api/">my last post</a> about performance testing I wrote about how we decided to do it in production as the ultimate test of success. Performance testing in production is enough to make some operations guys have a panic attack and a few odd looks were dished my way when I raised it on behalf of the team.</p>
<h2 id="Why-not-have-a-dedicated-environment"><a href="#Why-not-have-a-dedicated-environment" class="headerlink" title="Why not have a dedicated environment?"></a>Why not have a dedicated environment?</h2><p>If you can have a dedicated environment that you can build to be EXACTLY the same as where you are going to really need the performance (i.e. your production environment most likely, but possibly on a client machine) then do it in a dedicated, duplicated environment. Alternatively if there is no way you can use the production environment or your model means that everything will scale exactly like production, then a duplicate environment might work.</p>
<p>For us, we had too many dependencies, mocking these out wasn’t really satisfactory and frankly, as a business where we are quiet at night, it is easy to use the production environment at these times. We use configuration management and virtual machines, much of what should help build a replica environment, but we also have machines in restaurants around the globe. That is not easy to replicate and not worth the effort.</p>
<h2 id="Even-if-you-can-have-a-duplicated-environment-should-you"><a href="#Even-if-you-can-have-a-duplicated-environment-should-you" class="headerlink" title="Even if you can have a duplicated environment should you?"></a>Even if you can have a duplicated environment should you?</h2><p>We felt in the search team that we just wouldn’t uncover a broken server (that can affect performance) or we wouldn’t see that we had a problem with interactions with these services (we have now got to serialisation as our bottleneck, maybe we would have missed that).</p>
<p>We just didn’t trust that a duplicated environment would actually help us in this case. If you want to test a new idea as a prototype then the duplicate will probably work, even if just at first, we were trying to improve our actual environment.</p>
<h2 id="Is-testing-in-production-right"><a href="#Is-testing-in-production-right" class="headerlink" title="Is testing in production right?"></a>Is testing in production right?</h2><p>There is no ‘right’ answer here, plenty of people test in a duplicate environment and then monitor in production. I think this is probably a valid approach and in a lot of use cases this would be fine for us too.</p>
<p>Can you micro-optimise in a huge production system?  Probably not, so use a scaled down duplicate for that or even a local environment such as one created using Vagrant. Hopefully with enough micro-optimisations you will eventually see these in a larger environment.</p></div><a href="/blog/2014/03/20/when-to-performance-test-in-production/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/03/19/performance-testing-our-search-api/"><h2 class="post-title">Performance testing our Search API</h2></a><p class="post-meta">Posted on 19 March 2014 · <a href="/blog/categories/REST/" class="tag post-meta">REST</a> · <a href="/blog/categories/API/" class="tag post-meta">API</a> · <a href="/blog/categories/Benchmarks/" class="tag post-meta">Benchmarks</a> · <a href="/blog/categories/Performance/" class="tag post-meta">Performance</a></p><div class="post-entry"><p>It was midnight on the Friday before Christmas, my seven-week old child was tucked up asleep and I was pretty chilled. All was calm and it was time for bed. Two minutes later I had a phone call, followed by a series of Nagios email alerts, and a need to put my work hat on quickly. The search API was having trouble; as the manager of the team who developed it, I was not looking forward to this. We were having a real slowdown at one of our busiest times of the year &ndash; this was going to be fun.</p>
<p>Once the dust settled and we were back up and running we realised we needed to do a better job of performance testing and actually solve any performance issues. We <em>had</em> done some performance testing but clearly not the right kind.</p>
<h2 id="What-had-gone-wrong"><a href="#What-had-gone-wrong" class="headerlink" title="What had gone wrong?"></a>What had gone wrong?</h2><p>We were indexing our data too frequently, and under load it started to take a long time. We created a race condition where multiple indexing operations started happening. As each operation assumed the previous one had either failed or finished a vicious circle occurred making the situation worse and worse.</p>
<p>The simple fix was just to index the data less often or not at all if another operation was running, however we wanted to get to the bottom of why we slowed down under load which exposed this race condition, improve that speed and understand what is the maximum load the system can take.</p>
<h2 id="Getting-a-benchmark"><a href="#Getting-a-benchmark" class="headerlink" title="Getting a benchmark"></a>Getting a benchmark</h2><p>In order to know if we were actually making improvements we needed to be able to recreate load and see the impact. In order to do this and truly appreciate how it was going we needed to use our live environment &ndash; the only environment I felt we could truly understand. My next post will explain why we felt this was the best environment for the job.</p>
<p>With search and availability it is actually quite hard to use response times as a benchmark and the name of this exercise was really to cope with greater load. Response times are still nice to improve though so we were tracking them, but not using them as our main benchmark.</p>
<h2 id="Some-perspective-on-our-problem-domain"><a href="#Some-perspective-on-our-problem-domain" class="headerlink" title="Some perspective on our problem domain"></a>Some perspective on our problem domain</h2><p>We do not have a large index, in the tens of thousands of restaurants rather than millions of tweets for example. We have to merge in table availability (the fantastic thing about the OpenTable system) to the more static restaurant information. We also have large page sizes, needing to get up to 2,500 results out of one Elastic Search request. This proved to be relevant.</p></div><a href="/blog/2014/03/19/performance-testing-our-search-api/" class="post-read-more">[Read More]</a></article></div><ul class="pager main-pager"><li class="previous"><a href="/page/4">← Newer Posts</a></li><li class="next"><a href="/page/6">Older Posts →</a></li></ul></div></div></div><footer><div class="container beautiful-jekyll-footer"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href="https://github.com/opentable" title="GitHub"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-github"></i></span></a></li><li><a href="https://twitter.com/opentabletechuk" title="Twitter"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-twitter"></i></span></a></li><li><a href="https://www.linkedin.com/company/12181" title="LinkedIn"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-linkedin"></i></span></a></li><li><a href="http://stackoverflow.com/jobs/companies/opentable" title="StackOverflow"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-stack-overflow"></i></span></a></li></ul><p class="copyright text-muted">© OpenTable • 2019 • <a href="mailto:undefined"></a>
</p><p class="theme-by text-muted">Theme by
<a href="https://github.com/twoyao/beautiful-hexo">beautiful-hexo</a></p></div></div></div></footer><script src="/js/jquery-1.11.2.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/main.js"></script><script src="/js/highlight.min.js"></script><script>hljs.initHighlightingOnLoad();</script><script>(function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r;
    i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
    a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    m.parentNode.insertBefore(a, m)
})(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
ga('create', 'UA-2621903-16', 'auto');
ga('send', 'pageview');</script></body></html>