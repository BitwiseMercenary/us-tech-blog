<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><meta name="author" content="OpenTable"><link rel="icon" href="/favicon.png"><title>OpenTable Tech UK Blog</title><meta name="description"><link rel="alternate" type="application/rss+xml" title="OpenTable Tech UK Blog" href="/atom.xml"><link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/main.css"><script src="//fonts.otstatic.com/zys4lfz.js"></script><link rel="stylesheet" href="/css/highlight.css">
</head><body><nav class="navbar navbar-default navbar-fixed-top navbar-custom"><div class="container-fluid"><div class="navbar-header"><button type="button" data-toggle="collapse" data-target="#main-navbar" class="navbar-toggle"><span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button><a href="/" class="navbar-brand">OpenTable Tech UK Blog</a></div><div id="main-navbar" class="collapse navbar-collapse"><ul class="nav navbar-nav navbar-right"><li><a href="/about/">About</a></li><li><a href="/archives/">Archive</a></li><li><a href="/blog/authors/">Authors</a></li></ul></div><div class="avatar-container"><div class="avatar-img-border"><a href="/"><img src="/opentable.png" class="avatar-img"></a></div></div></div></nav><div id="header-big-imgs" data-num-img='3' data-img-src-1="/bigimgs/building.jpg" data-img-desc-1="Alphabeta Building" data-img-src-2="/bigimgs/kitchen.jpg" data-img-desc-2="OpenTable London office" data-img-src-3="/bigimgs/office.jpg" data-img-desc-3="OpenTable Engineers"></div><header class="header-section has-img"><div class="intro-header big-img"><div class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class="page-heading"><h1>OpenTable Tech UK Blog</h1><hr class="small"><span class="page-subheading">The technology blog for OpenTable UK.</span></div></div></div></div><span class="img-desc"></span></div></header><div role="main" class="container"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class="posts-list"><article class="post-preview"><a href="/blog/2014/04/04/testing-puppet-with-beaker/"><h2 class="post-title">Testing Puppet with Beaker</h2></a><p class="post-meta">Posted on 4 April 2014</p><div class="post-entry"><p>One afternoon I got asked to write a new Puppet module to manage local users on our Linux boxes. Not a contrived example but a real-world need as we begin to move our infrastructure from Windows to Linux. Managing users is one of those tasks that is at the core of the Puppet ecosystem and I thought this would be pretty easy as I had done this sort of thing many times before. What added to the complexity was that we needed to support Ubuntu, Centos and FreeBSD machines that we had in our stack and we wanted to make it something that was open source and on the Forge - so lots of testing was required.</p>
<p>This was not the first module that I had written for the Forge but it was the first that I had written since PuppetLabs had introduced their new acceptance testing framework <a href="https://github.com/puppetlabs/beaker" target="_blank" rel="external">Beaker</a> and so I wanted to spend some time getting the module working with this new tool.</p>
<h2 id="Beaker"><a href="#Beaker" class="headerlink" title="Beaker"></a>Beaker</h2><p>The purpose of Beaker is to allow you to write acceptance tests for your modules, that is to write some manifests that use your module and test them out on a virtual machine. Some of you may remember <a href="https://github.com/puppetlabs/rspec-system-puppet" target="_blank" rel="external">rspec-system-puppet</a> was previously used to accomplish this, well PuppetLabs has since deprecated that in favour of Beaker but the premise is very much the same.</p>
<p>Using rspec-puppet for unit testing your manifests really only goes so far. If you’re just using the standard Puppet resources then it pretty safe to assume that it does what it says on the tin (I mean PuppetLabs really test their stuff!) but as soon as you start doing things that are a little more complex, using exec statements, custom facts, custom functions or targeting multiple operating systems then you’re really going to want to make sure that once the catalogs compile that they are doing what they are meant to be doing and this is where your acceptance test suite will come in.</p>
<p>With Beaker you can spin up a virtual machine, install modules, apply a manifest and then test what really happened.</p>
<p>Beaker works with many different hypervisor technologies but most people will be using <a href="http://www.vagrantup.com/" target="_blank" rel="external">Vagrant</a> so that is what I will cover here.</p>
<h3 id="Configuring-Beaker"><a href="#Configuring-Beaker" class="headerlink" title="Configuring Beaker"></a>Configuring Beaker</h3><p>The first thing in configuring your existing project to use Beaker is to add “beaker” and “beaker_rspec” to you Gemfile. You’re then going to want to create a new spec_helper file called spec_helper_acceptence.rb that should look something like this:</p>
<pre><code>require &apos;beaker-rspec/spec_helper&apos;
require &apos;beaker-rspec/helpers/serverspec&apos;

hosts.each do |host|
  install_puppet
end

UNSUPPORTED_PLATFORMS = [&apos;Suse&apos;,&apos;windows&apos;,&apos;AIX&apos;,&apos;Solaris&apos;]

RSpec.configure do |c|
  proj_root = File.expand_path(File.join(File.dirname(__FILE__), &apos;..&apos;))

  c.formatter = :documentation

  # Configure all nodes in nodeset
  c.before :suite do
    puppet_module_install(:source =&gt; proj_root, :module_name =&gt; &apos;homes&apos;)
    hosts.each do |host|
      on host, puppet(&apos;module&apos;,&apos;install&apos;,&apos;puppetlabs-stdlib&apos;), { :acceptable_exit_codes =&gt; [0,1] }
      on host, puppet(&apos;module&apos;, &apos;install&apos;, &apos;opentable-altlib&apos;), { :acceptable_exit_codes =&gt; [0,1] }
    end
  end
end
</code></pre></div><a href="/blog/2014/04/04/testing-puppet-with-beaker/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/04/04/forgefriday-our-commitment-to-the-puppet-forge/"><h2 class="post-title">ForgeFriday - our commitment to the Puppet Forge</h2></a><p class="post-meta">Posted on 4 April 2014 · <a href="/blog/categories/OSS/" class="tag post-meta">OSS</a> · <a href="/blog/categories/Puppet/" class="tag post-meta">Puppet</a> · <a href="/blog/categories/Open-souce/" class="tag post-meta">Open souce</a></p><div class="post-entry"><p>Those of you that read this blog on a regular basis will be aware that here at OpenTable we take our commitment to Open Source very seriously. As part of the infrastructure team at OpenTable we are begining a process of being open-first. That means that everything we write will be open-sourced unless it contains a significant amount of internal information but we will architect to limit this.</p>
<p>As part of that commitment we are trying to release all our Puppet configuration. The key to maintaining any good habit is to do little and often and with that in mind we wanted to let you know about ForgeFriday.</p>
<p>Every Friday we will be releasing our Puppet code onto the <a href="http://forge.puppetlabs.com/opentable" target="_blank" rel="external">PuppetLabs Forge</a> (until we run out of modules). That means all our Windows modules, all our forks, our experiments, our custom facts and functions - anything and everything will start rolling out on Fridays. </p>
<p>It’s not just forge and forget either, we will continue to support all of our modules and those that use them. We will blog about some of the bigger, more important ones and continue to engage with the community as much as possible. If you’re using our modules (even if you have no issues) then let us know - we’d love to hear from you.</p>
<p>In the meantime go and check out what we have already released:</p>
<p><a href="http://forge.puppetlabs.com/opentable/windowsfeature" target="_blank" rel="external">opentable/windowsfeature</a> - Module that will turn Windows features on or off<br><br><a href="http://forge.puppetlabs.com/opentable/iis_rewrite" target="_blank" rel="external">opentable/iis_rewrite</a> - Module that will install the IIS Rewrite 2.0 Module on Windows <br><br><a href="http://forge.puppetlabs.com/opentable/remaster" target="_blank" rel="external">opentable/remaster</a> - Module for managing the remaster of agent nodes <br><br><a href="http://forge.puppetlabs.com/opentable/puppetversion" target="_blank" rel="external">opentable/puppetversion</a> - Module for managing the installation and upgrade of Puppet<br><br><a href="http://forge.puppetlabs.com/opentable/altlib" target="_blank" rel="external">opentable/altlib</a> - Module providing some additional useful functions <br></p>
<p>Keep an eye on Twitter for the latest ForgeFriday updates.</p>
</div><a href="/blog/2014/04/04/forgefriday-our-commitment-to-the-puppet-forge/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/04/02/internationalisation-in-a-restful-world/"><h2 class="post-title">Internationalisation in a RESTful world</h2></a><p class="post-meta">Posted on 2 April 2014 · <a href="/blog/categories/REST/" class="tag post-meta">REST</a> · <a href="/blog/categories/API/" class="tag post-meta">API</a> · <a href="/blog/categories/i18n/" class="tag post-meta">i18n</a> · <a href="/blog/categories/Internationalisation/" class="tag post-meta">Internationalisation</a> · <a href="/blog/categories/http/" class="tag post-meta">http</a></p><div class="post-entry"><p>I18n is often a painful afterthought when serving content from a http-api. It can be taken for granted and tacked on using nasty query string values. But thankfully HTTP provides us with a solid gold opportunity. If you can look past the mire of content negotiation you can see the nuggets that lie inside.</p>
<p>The accept-language header is used by most browsers and allows websites to serve content in a language that the user can (hopefully) understand. When we expose content from an api (in most of our use cases, at least), this content eventually ends up in front of a human (in some shape or form). Having our service-service communication serve localised resources can be invaluable because it frees the clients from having to think about i18n of the resources being served from our api.</p>
<p>It is a simple part of the HTTP specification and is widely used and supported.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET /product/123</span><br><span class="line">Accept-Language: en-US</span><br></pre></td></tr></table></figure>
<p>The accept-language header is specifically designed to allow the server to provide a representation of the resource which approximates something the client can understand.</p>
<p>The really useful bit comes from the quality value. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET /product/123</span><br><span class="line">Accept-Language: en-US,en;q=0.8</span><br></pre></td></tr></table></figure>
<p>This header asks the service to provide en-US, and if it’s unavailable then fall back to <strong>any</strong> english representation. The quality value (<code>q=0.8</code>) is a decimal value between 0 and 1 which indicates order of preference when specifying multiple languages. The server should pick the <strong>first</strong> available match. If there are multiple matches with the same quality value, then the server can pick any. If the client wants to specify some fierce preferences then they can crank out something like this:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GET /product/123</span><br><span class="line">Accept-Language: fr-CA,fr-FR;q=0.8,fr;q=0.6,en-US;q=0.4,en;q=0.2,*;q=0.1</span><br></pre></td></tr></table></figure>
<p>If you decipher this it’s pretty simple, you can see the quality headers giving the order in which the languages are preferred. What it does is give the client fantastic flexibility. For service-service communication you might have a use-case which will <em>never</em> serve a representation that doesn’t match the request, or you might need to <em>always</em> provide some representation (i.e. for cases where some content is always better than none).</p></div><a href="/blog/2014/04/02/internationalisation-in-a-restful-world/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/03/20/when-to-performance-test-in-production/"><h2 class="post-title">When to performance test in production</h2></a><p class="post-meta">Posted on 20 March 2014 · <a href="/blog/categories/Performance/" class="tag post-meta">Performance</a></p><div class="post-entry"><p>In <a href="/blog/2014/03/19/performance-testing-our-search-api/">my last post</a> about performance testing I wrote about how we decided to do it in production as the ultimate test of success. Performance testing in production is enough to make some operations guys have a panic attack and a few odd looks were dished my way when I raised it on behalf of the team.</p>
<h2 id="Why-not-have-a-dedicated-environment"><a href="#Why-not-have-a-dedicated-environment" class="headerlink" title="Why not have a dedicated environment?"></a>Why not have a dedicated environment?</h2><p>If you can have a dedicated environment that you can build to be EXACTLY the same as where you are going to really need the performance (i.e. your production environment most likely, but possibly on a client machine) then do it in a dedicated, duplicated environment. Alternatively if there is no way you can use the production environment or your model means that everything will scale exactly like production, then a duplicate environment might work.</p>
<p>For us, we had too many dependencies, mocking these out wasn’t really satisfactory and frankly, as a business where we are quiet at night, it is easy to use the production environment at these times. We use configuration management and virtual machines, much of what should help build a replica environment, but we also have machines in restaurants around the globe. That is not easy to replicate and not worth the effort.</p>
<h2 id="Even-if-you-can-have-a-duplicated-environment-should-you"><a href="#Even-if-you-can-have-a-duplicated-environment-should-you" class="headerlink" title="Even if you can have a duplicated environment should you?"></a>Even if you can have a duplicated environment should you?</h2><p>We felt in the search team that we just wouldn’t uncover a broken server (that can affect performance) or we wouldn’t see that we had a problem with interactions with these services (we have now got to serialisation as our bottleneck, maybe we would have missed that).</p>
<p>We just didn’t trust that a duplicated environment would actually help us in this case. If you want to test a new idea as a prototype then the duplicate will probably work, even if just at first, we were trying to improve our actual environment.</p>
<h2 id="Is-testing-in-production-right"><a href="#Is-testing-in-production-right" class="headerlink" title="Is testing in production right?"></a>Is testing in production right?</h2><p>There is no ‘right’ answer here, plenty of people test in a duplicate environment and then monitor in production. I think this is probably a valid approach and in a lot of use cases this would be fine for us too.</p>
<p>Can you micro-optimise in a huge production system?  Probably not, so use a scaled down duplicate for that or even a local environment such as one created using Vagrant. Hopefully with enough micro-optimisations you will eventually see these in a larger environment.</p></div><a href="/blog/2014/03/20/when-to-performance-test-in-production/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/03/19/performance-testing-our-search-api/"><h2 class="post-title">Performance testing our Search API</h2></a><p class="post-meta">Posted on 19 March 2014 · <a href="/blog/categories/REST/" class="tag post-meta">REST</a> · <a href="/blog/categories/API/" class="tag post-meta">API</a> · <a href="/blog/categories/Benchmarks/" class="tag post-meta">Benchmarks</a> · <a href="/blog/categories/Performance/" class="tag post-meta">Performance</a></p><div class="post-entry"><p>It was midnight on the Friday before Christmas, my seven-week old child was tucked up asleep and I was pretty chilled. All was calm and it was time for bed. Two minutes later I had a phone call, followed by a series of Nagios email alerts, and a need to put my work hat on quickly. The search API was having trouble; as the manager of the team who developed it, I was not looking forward to this. We were having a real slowdown at one of our busiest times of the year &ndash; this was going to be fun.</p>
<p>Once the dust settled and we were back up and running we realised we needed to do a better job of performance testing and actually solve any performance issues. We <em>had</em> done some performance testing but clearly not the right kind.</p>
<h2 id="What-had-gone-wrong"><a href="#What-had-gone-wrong" class="headerlink" title="What had gone wrong?"></a>What had gone wrong?</h2><p>We were indexing our data too frequently, and under load it started to take a long time. We created a race condition where multiple indexing operations started happening. As each operation assumed the previous one had either failed or finished a vicious circle occurred making the situation worse and worse.</p>
<p>The simple fix was just to index the data less often or not at all if another operation was running, however we wanted to get to the bottom of why we slowed down under load which exposed this race condition, improve that speed and understand what is the maximum load the system can take.</p>
<h2 id="Getting-a-benchmark"><a href="#Getting-a-benchmark" class="headerlink" title="Getting a benchmark"></a>Getting a benchmark</h2><p>In order to know if we were actually making improvements we needed to be able to recreate load and see the impact. In order to do this and truly appreciate how it was going we needed to use our live environment &ndash; the only environment I felt we could truly understand. My next post will explain why we felt this was the best environment for the job.</p>
<p>With search and availability it is actually quite hard to use response times as a benchmark and the name of this exercise was really to cope with greater load. Response times are still nice to improve though so we were tracking them, but not using them as our main benchmark.</p>
<h2 id="Some-perspective-on-our-problem-domain"><a href="#Some-perspective-on-our-problem-domain" class="headerlink" title="Some perspective on our problem domain"></a>Some perspective on our problem domain</h2><p>We do not have a large index, in the tens of thousands of restaurants rather than millions of tweets for example. We have to merge in table availability (the fantastic thing about the OpenTable system) to the more static restaurant information. We also have large page sizes, needing to get up to 2,500 results out of one Elastic Search request. This proved to be relevant.</p></div><a href="/blog/2014/03/19/performance-testing-our-search-api/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/02/28/api-benchmark/"><h2 class="post-title">Benchmarking APIs - why it’s important, and how</h2></a><p class="post-meta">Posted on 28 February 2014 · <a href="/blog/categories/REST/" class="tag post-meta">REST</a> · <a href="/blog/categories/API/" class="tag post-meta">API</a> · <a href="/blog/categories/Benchmarks/" class="tag post-meta">Benchmarks</a> · <a href="/blog/categories/SOA/" class="tag post-meta">SOA</a> · <a href="/blog/categories/Node-js/" class="tag post-meta">Node.js</a> · <a href="/blog/categories/Performance/" class="tag post-meta">Performance</a> · <a href="/blog/categories/Continuous-delivery/" class="tag post-meta">Continuous delivery</a></p><div class="post-entry"><p>Since I joined OpenTable I’ve been experimenting with performance monitoring, specifically on web services. One of the projects my team is responsible for is a REST API that provides UI elements for HTML5 applications, shaped as HTML snippets and static resources. Our consumers are websites deployed in multiple parts of the world, so our service needs to be fast and reliable.</p>
<h2 id="The-why"><a href="#The-why" class="headerlink" title="The why"></a>The why</h2><p>A couple of weeks after joining the company I decided, as part of my <a href="/blog/2014/02/06/20-percent-time/">innovation time</a>, to rebuild the core of a .NET WebApi project in node.js in order to have a working prototype that could do exactly the same job as the original one, and could help me to observe how the two applications could react with similar volumes of traffic. After managing to make the two apis run on two clean VMs with the same configuration, I wrote a little node.js script to start performing some requests and test the response times. After seeing the results I thought that something was going wrong:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">.NET/route1 x 9.16 ops/sec ±12.71% (17 runs sampled)</span><br><span class="line">nodeJS/route1 x 106 ops/sec ±1.19% (180 runs sampled)</span><br><span class="line">======================================</span><br><span class="line">Fastest is nodeJS/route1</span><br><span class="line"> </span><br><span class="line">.NET/route2 x 10.70 ops/sec ±8.54% (19 runs sampled)</span><br><span class="line">nodeJS/route2 x 118 ops/sec ±1.22% (175 runs sampled)</span><br><span class="line">======================================</span><br><span class="line">Fastest is nodeJS/route2</span><br><span class="line"> </span><br><span class="line">======================================</span><br><span class="line">Fastest Service is nodeJS</span><br></pre></td></tr></table></figure>
<p>After trying to microbenchmark different layers of the software, I found the problem. On the .NET side I was reading a file synchronously, for every request; the file system’s library used with the node.js app, instead, was automatically caching the reads as default. After setting up a basic caching mechanism in the .NET app and running my script again the node.js API was only 1.4 times faster. After finding and solving that issue I thought how badly the application could have handled concurrency when deployed in production, even if it was heavily unit tested, the specs were well defined, and it was built using all the best techniques we all love.</p>
<p>As developers we rely on technologies that, with a minimum effort, can guarantee some pretty decent results in terms of performance. Modern web frameworks handle concurrency and thread management without requiring much plumbing code. Sophisticated and relatively cheap cloud services help us monitor our applications, providing dashboards, reports and alerting systems. Deploying on the cloud we can run our services and even auto-scale them depending on how much power we need. Even with these tools we must still own the responsibility of writing good quality code, testing it properly, and deploying as fast as possible in order to optimise the delivery process of our products. </p>
<p>But what about performance? I mean, what about the relationship between the code we write every day, and the way we impact overall performance? Are we sure that we are not deploying to production something that is degrading our services’ performance?</p>
<h2 id="The-how"><a href="#The-how" class="headerlink" title="The how"></a>The how</h2><p>Talking about the ‘why’ could be relatively easy, but the ‘how’ is a controversial topic. In my experience there are three important steps to any dish. First, we need the right tools to manipulate the ingredients. I tried many different tools but I couldn’t find a good fit for all my benchmarking requirements. It always makes sense to start with something to get you going but after a while it is important to find what’s the best for you, your team, and your project.</p>
<p>Then, you start cooking: personally, the number of things I’ve learned by just starting to benchmark some services is incredible. Nevertheless, as with every time we talk about metrics, it is key to know what is important about the data we are analysing, recognise the false positives/negatives and be aware of vanity metrics that could emphasize something irrelevant, or, more importantly, hide something significant.</p></div><a href="/blog/2014/02/28/api-benchmark/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/02/12/programme-management/"><h2 class="post-title">Programme Management, making Agile scale</h2></a><p class="post-meta">Posted on 12 February 2014 · <a href="/blog/categories/Leadership/" class="tag post-meta">Leadership</a> · <a href="/blog/categories/Conferences/" class="tag post-meta">Conferences</a> · <a href="/blog/categories/Agile/" class="tag post-meta">Agile</a></p><div class="post-entry"><h2 id="Popular-topic-at-conferences"><a href="#Popular-topic-at-conferences" class="headerlink" title="Popular topic at conferences"></a>Popular topic at conferences</h2><p>A lot of us were lucky enough to attend NDC London this year, we even sponsored one of the food stalls. I often see one or more real themes coming from talks at conferences. At NDC London I saw three talks around scaling Agile. Indeed Dan North’s (<a href="https://twitter.com/tastapod" target="_blank" rel="external">@tastapod</a>) talk was called exactly that. It is a topic OpenTable is trying to make happen. We are about 100 engineers on three continents which is a lot of teams working together.</p>
<p>I truly believe that the only way to make an individual team successful in an Agile environment is to have ownership of an area, a system or similar. That enables fast feedback, quick decision making and also a sense of pride and responsibility for what people are working on.</p>
<p>However, when you have a big project, you can’t give it to just one team. You need many teams working together. You can split it up and get teams to work on the parts of the project affecting the code they own. This will though mean certain parts of the project go faster than others, and if teams are autonomous, who is really responsible for bringing all those pieces together? Also, imagine you are the project owner and need to have a rough handle on when things can actually be delivered, who is going to give you that? None of the individual teams know, everyone is Agile and cool and so everyone hates estimates.</p>
<p>The point made by three speakers at NDC London, <a href="https://twitter.com/tastapod" target="_blank" rel="external">Dan North</a>, <a href="https://twitter.com/jezhumble" target="_blank" rel="external">Jez Humble</a> and <a href="https://twitter.com/gojkoadzic" target="_blank" rel="external">Gojko Adzic</a> came down to the need for the coordination piece across the teams. One thing Dan North (more or less) said is <em>“if your team is really fast and all the others are slow, the project is slow and your team haven’t achieved their goal”</em>. That was not the exact words he used but the sentiment came across. </p>
<p>Indeed we have some big projects at OpenTable and as we have properly embraced Agile in many ways, we still had some pain points in this exact area. We were getting to the same conclusions but since these talks we have had some more solid programme management and in the third cross-team meeting as a result, things starting taking shape. It really is an important piece of the jigsaw.</p>
<p>I would also recommend a <a href="http://www.youtube.com/watch?v=ILP1pJAuT9c&amp;list=PLBMFXMTB7U74NdDghygvBaDcp67owVUUF&amp;feature=c4-overview-vl" target="_blank" rel="external">DevDay talk</a> from Dariusz Dziuk on this and how Spotify make things scale. Slightly different content but a similar theme.</p>
</div><a href="/blog/2014/02/12/programme-management/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/02/10/the-adoption-of-configuration-management/"><h2 class="post-title">The adoption of Configuration Management</h2></a><p class="post-meta">Posted on 10 February 2014 · <a href="/blog/categories/Puppet/" class="tag post-meta">Puppet</a> · <a href="/blog/categories/DevOps/" class="tag post-meta">DevOps</a> · <a href="/blog/categories/Configuration-management/" class="tag post-meta">Configuration management</a></p><div class="post-entry"><p>In years gone by, we were a traditional IT company. We had teams of developers and operations. They rarely mixed. Around nine months ago we started to really try and get these teams working together. We introduced a configuration management tool, <a href="http://puppetlabs.com/puppet/what-is-puppet" target="_blank" rel="external">Puppet</a>, into our ecosystem. </p>
<p>Configuration management is one of the steps of continuous delivery that developers often forget. They feel that systems are magically created for them to deploy their application to. I used to believe this. When I was focused on developing software, I never gave any thought as to the work our operations team had to do to keep the train on the track. So give some respect to your operations teams! We created a repository and started to experiment by configuring some of our applications using Puppet. </p>
<p>This was a major step for both sets of teams. The developers started being in charge of the configuration of their application. This meant that their application would guarantee to be configured the same in our CI environment as it was in production. We, as developers, would be more confident of our applications working as expected. </p>
<p>To contribute to the project, as an engineer, you need to:</p>
<ul>
<li>fork the project</li>
<li>make the changes you require</li>
<li>test the changes in a Vagrant environment (already created with a Windows and Linux system)</li>
<li>send a PR (pull request)</li>
</ul>
<p>We have just merged our #847 pull request. The stats of the repository look as follows:</p>
<img src="/images/posts/puppet-adoption.png" class="center">
<p>Our puppet repository has had contributions from over 40% of our engineering / operations teams. We use Puppet to manage our application servers, DHCP servers, provisioning systems and even our MS Sql Server continuous integration infrastructure. The adoption has been fantastic. We started by running our internal QA infrastructure and then scaled it out to our production infrastructure. We now manage 548 nodes (a combination of internal and production) via Puppet. </p>
<p>Using a project called <a href="www.fullybaked.co.uk/articles/getting-gource-running-on-osx">Gource</a>, one of our engineering leads, <a href="http://twitter.com/ryantomlinson" target="_blank" rel="external">Ryan Tomlinson</a>, created a video of the repository vizualization. It’s just over two minutes long and shows the activity the repository has taken.</p>
<div class="video-container"><iframe src="//player.vimeo.com/video/86201508" frameborder="0" allowfullscreen></iframe></div></div><a href="/blog/2014/02/10/the-adoption-of-configuration-management/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/02/06/20-percent-time/"><h2 class="post-title">20% time: Why, as a manager, you should love your engineers to be doing it</h2></a><p class="post-meta">Posted on 6 February 2014 · <a href="/blog/categories/Leadership/" class="tag post-meta">Leadership</a></p><div class="post-entry"><p>We allow all our UK based developers to have some time to explore new technologies, try out prototypes and clean-up things that escape the day-to-day process. Two days out of ten, seems a lot doesn’t it?</p>
<h2 id="How-we-started"><a href="#How-we-started" class="headerlink" title="How we started"></a>How we started</h2><p>We started doing our 20% time when we had two week sprints with a release each sprint. We actually had three days of testing, small bug fixing and signing things off. We didn’t like starting our new stories for the next sprint as our QAs got behind and never really caught up. We decided to use this time more for clean-up but also for prototyping or trying something out. We had read of other companies doing something similar so were excited to give it a go. </p>
<p>One of the first times we did this we actually decided we wanted to automate all the testing of one of our systems, so that our QAs weren’t bogged down for those three days. In our first 20% time, we got most of the team on board as it was painful watching, let alone doing manual testing and we wanted faster feedback on our changes.</p>
<p>We got a lot of the system in a state we could test it. We basically wrote a lot of a page object model and a few features to talk to it. The next 20% time it needed cleaning up, the next we had a lot under test. With a bit of work the three day test cycle was down to about one day. This would never have happened if we were trying in normal sprint time. Major win number one and something no business owner had had to wrestle against other priorities.</p>
<p>After this instance we have had numerous similar examples, albeit on a smaller scale, where each team has been able to try things out, with no consequence in the event of failure, and achieved great prototypes. Much of our new architecture has been tested out in these sessions, new technologies, new approaches, can people work together?</p>
<h2 id="Failures-not-so-bad-after-all"><a href="#Failures-not-so-bad-after-all" class="headerlink" title="Failures, not so bad after all"></a>Failures, not so bad after all</h2><p>Of course, we have had many failures, but maybe even that helps, we won’t waste our proper sprint time. Some people ask me about rules when I talk about this. I think the key for me is that the engineers are truly given freedom to explore. If on the face of things something they are doing is completely away from what you are doing then it might seem a bit strange.</p>
<p>But what if they are looking to try something new and would have left your company to do so? What if they think it might be a solution but don’t know how to say? What if they can use it in nine months on an urgent project? All these things can and have happened.</p>
<h2 id="Fear-as-always-is-detrimental"><a href="#Fear-as-always-is-detrimental" class="headerlink" title="Fear, as always, is detrimental"></a>Fear, as always, is detrimental</h2></div><a href="/blog/2014/02/06/20-percent-time/" class="post-read-more">[Read More]</a></article><article class="post-preview"><a href="/blog/2014/02/03/coaching-style-over-substance/"><h2 class="post-title">Coaching style over substance</h2></a><p class="post-meta">Posted on 3 February 2014 · <a href="/blog/categories/Leadership/" class="tag post-meta">Leadership</a> · <a href="/blog/categories/Coaching/" class="tag post-meta">Coaching</a></p><div class="post-entry"><p>Have you ever been lucky enough to mentor someone who really got it? Maybe you’ve had the opposite experience and the session ended up being a failure for both of you?</p>
<p>We are fortunate enough to be in an industry that gives us the chance to coach others and have a direct influence on the learning of individuals around us. But how do we know when we’re doing it right, or more importantly what can we do when it starts to go wrong?</p>
<h2 id="Know-your-student-find-their-style"><a href="#Know-your-student-find-their-style" class="headerlink" title="Know your student, find their style"></a>Know your student, find their style</h2><p>Let’s start with the science behind how we learn.</p>
<p>The first recognised attempt to identify different approaches individuals use in order to learn was David Kolb with the book ‘<a href="http://www.amazon.co.uk/Experiential-Learning-Experience-Source-Development/dp/0132952610" target="_blank" rel="external">Experimental Learning</a>‘. Kolb suggested that humans have a range of learning techniques available to us and that we tend to lean on one learning style above all others.</p>
<p>In recent times his research has proved to be inaccurate - yes people have different learning styles, yes they  show an emphasis in one particular style but Kolb’s definition of separate styles was confused. </p>
<p>Enter <a href="http://en.wikipedia.org/wiki/Learning_styles#Peter_Honey_and_Alan_Mumford.27s_model" target="_blank" rel="external">Honey and Mumford and their 1999 adaptation on Kolb’s model</a>. They identified four distinct learning styles which have since grown to be the preferred assessment of human learning styles. </p>
<table style="font-size: 80%;margin-bottom:20px;"><br>    <tr><br>        <th style="padding:3px;"></th><br>        <th style="padding:3px;"><b>Description</b></th><br>        <th style="padding:3px;"><b>Learn best</b></th><br>        <th style="padding:3px;"><b>Learn worst</b></th><br>    </tr><br>    <tr style="background-color: #E5E5E5"><br>        <td style="padding:3px;vertical-align:top;"><b>Activists</b></td><br>        <td style="padding:3px;vertical-align:top;">Enjoy doing, tend to act first and think later. They like working with others but often hog the limelight.</td><br>        <td style="padding:3px;vertical-align:top;">When involved in new experiences, being thrown in the deep end and leading discussions.</td><br>        <td style="padding:3px;vertical-align:top;">Listening to long lectures, reading or writing on their own. Following precise information to the letter.</td><br>    </tr><br>    <tr><br>        <td style="padding:3px;vertical-align:top;"><b>Reflectors</b></td><br>        <td style="padding:3px;vertical-align:top;">Like to stand back, listen to others, look at the situation, gather data and carefully come to a conclusion.</td><br>        <td style="padding:3px;vertical-align:top;">Observing individuals or teams at work,  reviewing what has happened and what they have learned from it.</td><br>        <td style="padding:3px;vertical-align:top;">Acting as a leader in front of others, doing things without preparation, being rushed by deadlines.</td><br>    </tr><br>    <tr style="background-color: #E5E5E5"><br>        <td style="padding:3px;vertical-align:top;"><b>Theorists</b></td><br>        <td style="padding:3px;vertical-align:top;">Able to adapt and integrate observations into complex theories. Tend to be perfectionists. Detached and analytical rather than emotive.</td><br>        <td style="padding:3px;vertical-align:top;">When put into complex and structured situations having to apply their skill and knowledge. Have the chance to question and probe ideas.</td><br>        <td style="padding:3px;vertical-align:top;">With unstructured or poorly briefed activities. Will struggle in situations where emphasise is put on emotion or feelings.</td><br>    </tr><br>    <tr><br>        <td style="padding:3px;vertical-align:top;"><b>Pragmatists</b></td><br>        <td style="padding:3px;vertical-align:top;">Practical and down to earth. Keen to try things out they can be impatient especially with long discussions.</td><br>        <td style="padding:3px;vertical-align:top;">Respond well to demonstrations of techniques that show an obvious advantage.</td><br>        <td style="padding:3px;vertical-align:top;">Learning is all theory. No guidelines on how to accomplish activity. No apparent pay back.</td><br>    </tr><br></table>

<p>The important thing to remember is not all individuals can be pigeon-holed into one group. These characteristics are evident across all industries and teams; I can certainly see myself and others in this list. Can you?</p>
<p>Now we can silo and identify behaviour, we can look deeper into the flow of learning.</p></div><a href="/blog/2014/02/03/coaching-style-over-substance/" class="post-read-more">[Read More]</a></article></div><ul class="pager main-pager"><li class="previous"><a href="/page/4">← Newer Posts</a></li><li class="next"><a href="/page/6">Older Posts →</a></li></ul></div></div></div><footer><div class="container beautiful-jekyll-footer"><div class="row"><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center footer-links"><li><a href="https://github.com/opentable" title="GitHub"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-github"></i></span></a></li><li><a href="https://twitter.com/opentabletechuk" title="Twitter"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-twitter"></i></span></a></li><li><a href="https://www.linkedin.com/company/12181" title="LinkedIn"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-linkedin"></i></span></a></li><li><a href="http://stackoverflow.com/jobs/companies/opentable" title="StackOverflow"><span class="fa-stack fa-lg"><i class="fa fa-circle fa-stack-2x"></i><i class="fa fa-stack-1x fa-inverse fa-stack-overflow"></i></span></a></li></ul><p class="copyright text-muted">© OpenTable • 2017 • <a href="mailto:undefined"></a>
</p><p class="theme-by text-muted">Theme by
<a href="https://github.com/twoyao/beautiful-hexo">beautiful-hexo</a></p></div></div></div></footer><script src="/js/jquery-1.11.2.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/main.js"></script><script src="/js/highlight.min.js"></script><script>hljs.initHighlightingOnLoad();</script><script>(function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r;
    i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
    a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    m.parentNode.insertBefore(a, m)
})(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
ga('create', 'UA-2621903-16', 'auto');
ga('send', 'pageview');</script></body></html>